{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as pst\n",
    "import pyspark.sql.functions as psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_LEVEL = os.environ.get(\"LOG_LEVEL\", \"INFO\")\n",
    "\n",
    "RADIO_CODE_JSON_FILEPATH = os.environ.get(\"RADIO_CODE_JSON_FILEPATH\",\"./radio_code.json\")\n",
    "\n",
    "KAFKA_BROKER_URL = os.environ.get(\"KAFKA_BROKER_URL\", \"localhost:9092\")\n",
    "KAFKA_TOPIC = \"udacity.project.spark-streaming.police\"\n",
    "\n",
    "\n",
    "schema = pst.StructType([\n",
    "    pst.StructField(\"crime_id\", pst.StringType()),  # : \"183653763\",\n",
    "    pst.StructField(\"original_crime_type_name\", pst.StringType()),  # : \"Traffic Stop\",\n",
    "    pst.StructField(\"report_date\", pst.DateType()),  # : \"2018-12-31T00:00:00.000\",\n",
    "    pst.StructField(\"call_date\", pst.DateType()),  # : \"2018-12-31T00:00:00.000\",\n",
    "    pst.StructField(\"offense_date\", pst.DateType()),  # : \"2018-12-31T00:00:00.000\",\n",
    "    pst.StructField(\"call_time\", pst.StringType()),  # : \"23:57\",\n",
    "    pst.StructField(\"call_date_time\", pst.TimestampType()),  # : \"2018-12-31T23:57:00.000\",\n",
    "    pst.StructField(\"disposition\", pst.StringType()),  # : \"ADM\",\n",
    "    pst.StructField(\"address\", pst.StringType()),  # : \"Geary Bl/divisadero St\",\n",
    "    pst.StructField(\"city\", pst.StringType()),  # : \"San Francisco\",\n",
    "    pst.StructField(\"state\", pst.StringType()),  # : \"CA\",\n",
    "    pst.StructField(\"agency_id\", pst.StringType()),  # : \"1\",\n",
    "    pst.StructField(\"address_type\", pst.StringType()),  # : \"Intersection\",\n",
    "    pst.StructField(\"common_location\", pst.StringType()),  # : \"\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://08492a1435b7:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>KafkaSparkStructuredStreaming</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff65a72a860>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Create Spark in Standalone mode\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"KafkaSparkStructuredStreaming\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark\n",
    "    .readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_BROKER_URL)\n",
    "    .option(\"subscribe\", KAFKA_TOPIC)\n",
    "    .option(\"startingOffsets\", \"earliest\")\n",
    "    .option(\"maxOffsetsPerTrigger\", 6000)\n",
    "    .option(\"stopGracefullyOnShutdown\", \"true\")\n",
    "    .load()\n",
    ")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_df = df.selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "service_table = kafka_df.select(\n",
    "    psf.from_json(psf.col(\"value\"), schema).alias(\"parsed\")\n",
    ").select(\"parsed.*\")\n",
    "service_table.createOrReplaceTempView(\"service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    service_table\n",
    "    .writeStream\n",
    "    .outputMode(\"update\")\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"service_mem\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------\n",
      " crime_id                 | 182751009            \n",
      " original_crime_type_name | Suspicious Person    \n",
      " report_date              | 2018-10-02           \n",
      " call_date                | 2018-10-02           \n",
      " offense_date             | 2018-10-02           \n",
      " call_time                | 09:11                \n",
      " call_date_time           | 2018-10-02 09:11:00  \n",
      " disposition              | GOA                  \n",
      " address                  | 300 Block Of Hyde St \n",
      " city                     | San Francisco        \n",
      " state                    | CA                   \n",
      " agency_id                | 1                    \n",
      " address_type             | Premise Address      \n",
      " common_location          |                      \n",
      "-RECORD 1----------------------------------------\n",
      " crime_id                 | 182751010            \n",
      " original_crime_type_name | Passing Call         \n",
      " report_date              | 2018-10-02           \n",
      " call_date                | 2018-10-02           \n",
      " offense_date             | 2018-10-02           \n",
      " call_time                | 09:12                \n",
      " call_date_time           | 2018-10-02 09:12:00  \n",
      " disposition              | HAN                  \n",
      " address                  | Mission St/8th St    \n",
      " city                     | San Francisco        \n",
      " state                    | CA                   \n",
      " agency_id                | 1                    \n",
      " address_type             | Intersection         \n",
      " common_location          |                      \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * from service_mem\").show(2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0116aed6-3d32-43c0-8caa-a0995b6a39f2',\n",
       " 'runId': '168758d2-f103-43b4-b725-ff0d8ea43237',\n",
       " 'name': 'service_mem',\n",
       " 'timestamp': '2020-02-22T12:23:44.858Z',\n",
       " 'batchId': 27,\n",
       " 'numInputRows': 68,\n",
       " 'inputRowsPerSecond': 618.1818181818181,\n",
       " 'processedRowsPerSecond': 456.37583892617454,\n",
       " 'durationMs': {'addBatch': 45,\n",
       "  'getBatch': 0,\n",
       "  'getEndOffset': 0,\n",
       "  'queryPlanning': 22,\n",
       "  'setOffsetRange': 2,\n",
       "  'triggerExecution': 149,\n",
       "  'walCommit': 16},\n",
       " 'stateOperators': [],\n",
       " 'sources': [{'description': 'KafkaV2[Subscribe[udacity.project.spark-streaming.police]]',\n",
       "   'startOffset': {'udacity.project.spark-streaming.police': {'0': 11736}},\n",
       "   'endOffset': {'udacity.project.spark-streaming.police': {'0': 11804}},\n",
       "   'numInputRows': 68,\n",
       "   'inputRowsPerSecond': 618.1818181818181,\n",
       "   'processedRowsPerSecond': 456.37583892617454}],\n",
       " 'sink': {'description': 'MemorySink'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.stop()\n",
    "query.lastProgress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_agg_df = (\n",
    "    service_table\n",
    "    .withWatermark(\"call_date_time\", \"1 hour\") \n",
    "    .groupBy(\n",
    "        psf.window(service_table.call_date_time, \"30 minutes\"),\n",
    "        service_table.original_crime_type_name,\n",
    "        service_table.disposition,\n",
    "    ).count()\n",
    ")\n",
    "window_agg_df.createOrReplaceTempView(\"windowed_crime_types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    window_agg_df\n",
    "    .writeStream\n",
    "    .outputMode(\"update\")\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"agg_mem\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+------------------------+------------+-----+\n",
      "|window                                    |original_crime_type_name|disposition |count|\n",
      "+------------------------------------------+------------------------+------------+-----+\n",
      "|[2018-10-02 10:30:00, 2018-10-02 11:00:00]|Traf Violation Cite     |HAN         |1    |\n",
      "|[2018-10-02 14:30:00, 2018-10-02 15:00:00]|Threats / Harassment    |ND          |1    |\n",
      "|[2018-10-02 17:00:00, 2018-10-02 17:30:00]|Burglary                |REP         |2    |\n",
      "|[2018-10-02 17:30:00, 2018-10-02 18:00:00]|Passing Call            |HAN         |3    |\n",
      "|[2018-10-02 20:30:00, 2018-10-02 21:00:00]|Trespasser              |GOA         |2    |\n",
      "|[2018-10-02 21:30:00, 2018-10-02 22:00:00]|Trespasser              |HAN         |1    |\n",
      "|[2018-10-02 23:30:00, 2018-10-03 00:00:00]|Meet W/citizen          |HAN         |1    |\n",
      "|[2018-10-03 06:00:00, 2018-10-03 06:30:00]|Audible Alarm           |NCR         |1    |\n",
      "|[2018-10-03 06:30:00, 2018-10-03 07:00:00]|22500d                  |HAN         |1    |\n",
      "|[2018-10-03 13:00:00, 2018-10-03 13:30:00]|Prisoner Transport      |HAN         |1    |\n",
      "|[2018-10-03 13:00:00, 2018-10-03 13:30:00]|J/o                     |HAN         |1    |\n",
      "|[2018-10-03 13:00:00, 2018-10-03 13:30:00]|Well Being Check        |HAN         |1    |\n",
      "|[2018-10-03 13:00:00, 2018-10-03 13:30:00]|Traffic Stop            |HAN         |1    |\n",
      "|[2018-10-03 13:30:00, 2018-10-03 14:00:00]|Fight No Weapon         |Not recorded|1    |\n",
      "|[2018-10-03 20:00:00, 2018-10-03 20:30:00]|Poss                    |NOM         |1    |\n",
      "|[2018-10-03 20:30:00, 2018-10-03 21:00:00]|Caser                   |GOA         |1    |\n",
      "|[2018-10-03 22:00:00, 2018-10-03 22:30:00]|Wanted Vehicle / Sub    |REP         |1    |\n",
      "|[2018-10-04 10:00:00, 2018-10-04 10:30:00]|Assault / Battery Dv    |HAN         |1    |\n",
      "|[2018-10-04 12:00:00, 2018-10-04 12:30:00]|911                     |ADV         |4    |\n",
      "|[2018-10-04 12:00:00, 2018-10-04 12:30:00]|Mentally Disturbed      |HAN         |1    |\n",
      "+------------------------------------------+------------------------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * from agg_mem\n",
    "\"\"\").show(20, vertical=False, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'dac0272f-4a87-4058-aa4d-3c4ddd6b04bb',\n",
       " 'runId': 'cf71d657-79ef-4a9c-8961-607ffc311a0a',\n",
       " 'name': 'agg_mem',\n",
       " 'timestamp': '2020-02-22T12:32:38.934Z',\n",
       " 'batchId': 1,\n",
       " 'numInputRows': 6000,\n",
       " 'inputRowsPerSecond': 1146.1318051575931,\n",
       " 'processedRowsPerSecond': 2951.3034923757996,\n",
       " 'durationMs': {'addBatch': 1961,\n",
       "  'getBatch': 0,\n",
       "  'getEndOffset': 0,\n",
       "  'queryPlanning': 43,\n",
       "  'setOffsetRange': 1,\n",
       "  'triggerExecution': 2033,\n",
       "  'walCommit': 16},\n",
       " 'eventTime': {'avg': '2018-10-05T23:41:15.140Z',\n",
       "  'max': '2018-10-07T02:33:00.000Z',\n",
       "  'min': '2018-10-04T17:52:00.000Z',\n",
       "  'watermark': '2018-10-04T16:52:00.000Z'},\n",
       " 'stateOperators': [{'numRowsTotal': 8538,\n",
       "   'numRowsUpdated': 4333,\n",
       "   'memoryUsedBytes': 2369767,\n",
       "   'customMetrics': {'loadedMapCacheHitCount': 400,\n",
       "    'loadedMapCacheMissCount': 0,\n",
       "    'stateOnCurrentVersionSizeBytes': 2140999}}],\n",
       " 'sources': [{'description': 'KafkaV2[Subscribe[udacity.project.spark-streaming.police]]',\n",
       "   'startOffset': {'udacity.project.spark-streaming.police': {'0': 6000}},\n",
       "   'endOffset': {'udacity.project.spark-streaming.police': {'0': 12000}},\n",
       "   'numInputRows': 6000,\n",
       "   'inputRowsPerSecond': 1146.1318051575931,\n",
       "   'processedRowsPerSecond': 2951.3034923757996}],\n",
       " 'sink': {'description': 'MemorySink'}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.stop()\n",
    "query.lastProgress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "radio_code_df = spark.read.option(\"multiLine\", True).json(RADIO_CODE_JSON_FILEPATH)\n",
    "radio_code_df.createOrReplaceTempView(\"radio_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+\n",
      "|description|disposition_code|\n",
      "+-----------+----------------+\n",
      "|Abated     |ABA             |\n",
      "|Admonished |ADM             |\n",
      "|Advised    |ADV             |\n",
      "|Arrest     |ARR             |\n",
      "|Cancel     |CAN             |\n",
      "+-----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * from radio_code\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[window: struct<start:timestamp,end:timestamp>, original_crime_type_name: string, disposition: string, count: bigint, description: string, disposition_code: string]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_query = spark.sql(\"\"\"\n",
    "    SELECT ct.*, r.description\n",
    "    FROM windowed_crime_types as ct\n",
    "    LEFT JOIN radio_code as r on r.disposition_code = ct.disposition\n",
    "\"\"\")\n",
    "join_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    join_query\n",
    "    .writeStream\n",
    "    .outputMode(\"update\")\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"join_mem\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------\n",
      " window                   | [2018-10-02 10:30:00, 2018-10-02 11:00:00] \n",
      " original_crime_type_name | Traf Violation Cite                        \n",
      " disposition              | HAN                                        \n",
      " count                    | 1                                          \n",
      " description              | Handled                                    \n",
      " disposition_code         | HAN                                        \n",
      "-RECORD 1--------------------------------------------------------------\n",
      " window                   | [2018-10-02 14:30:00, 2018-10-02 15:00:00] \n",
      " original_crime_type_name | Threats / Harassment                       \n",
      " disposition              | ND                                         \n",
      " count                    | 1                                          \n",
      " description              | No Disposition                             \n",
      " disposition_code         | ND                                         \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * from join_mem\n",
    "\"\"\").show(2, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '35c01e4d-ff47-4e88-bddb-a03d447b1fec',\n",
       " 'runId': '4b2a3314-6cf3-4e74-b876-0f1dc95e3cd8',\n",
       " 'name': 'join_mem',\n",
       " 'timestamp': '2020-02-22T12:33:34.960Z',\n",
       " 'batchId': 3,\n",
       " 'numInputRows': 6000,\n",
       " 'inputRowsPerSecond': 2983.5902536051713,\n",
       " 'processedRowsPerSecond': 3227.5416890801507,\n",
       " 'durationMs': {'addBatch': 1786,\n",
       "  'getBatch': 0,\n",
       "  'getEndOffset': 0,\n",
       "  'queryPlanning': 42,\n",
       "  'setOffsetRange': 2,\n",
       "  'triggerExecution': 1859,\n",
       "  'walCommit': 11},\n",
       " 'eventTime': {'avg': '2018-10-10T20:58:40.429Z',\n",
       "  'max': '2018-10-12T06:27:00.000Z',\n",
       "  'min': '2018-10-09T15:00:00.000Z',\n",
       "  'watermark': '2018-10-09T14:00:00.000Z'},\n",
       " 'stateOperators': [{'numRowsTotal': 17173,\n",
       "   'numRowsUpdated': 4347,\n",
       "   'memoryUsedBytes': 4975391,\n",
       "   'customMetrics': {'loadedMapCacheHitCount': 1200,\n",
       "    'loadedMapCacheMissCount': 0,\n",
       "    'stateOnCurrentVersionSizeBytes': 4348359}}],\n",
       " 'sources': [{'description': 'KafkaV2[Subscribe[udacity.project.spark-streaming.police]]',\n",
       "   'startOffset': {'udacity.project.spark-streaming.police': {'0': 18000}},\n",
       "   'endOffset': {'udacity.project.spark-streaming.police': {'0': 24000}},\n",
       "   'numInputRows': 6000,\n",
       "   'inputRowsPerSecond': 2983.5902536051713,\n",
       "   'processedRowsPerSecond': 3227.5416890801507}],\n",
       " 'sink': {'description': 'MemorySink'}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.stop()\n",
    "query.lastProgress"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
